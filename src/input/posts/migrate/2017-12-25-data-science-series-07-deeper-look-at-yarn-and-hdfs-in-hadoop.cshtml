Title: "[Data Science 到底是什麼從一個完全外行角度來看][07]更深入看看Hadoop裡面的YARN和HDFS"
Published: 2017-12-25
Modified: 2018-02-10
Image: /posts/migrate/2017-12-25-data-science-series-07-deeper-look-at-yarn-and-hdfs-in-hadoop_Asset/image_thumb(66).png
Tags: ["hadoop","devops","「data science 到底是什麼從一個完全外行角度來看」"]
RedirectFrom: 2017/12/data-science-series-07-deeper-look-at-yarn-and-hdfs-in-hadoop.html
Series: ["「Data Science 到底是什麼從一個完全外行角度來看」"]
---
<section><figure><a href="https://lh3.googleusercontent.com/-dflngrHE-qU/WkD7gIKzbnI/AAAAAAAAXRM/JMY1-HAtKg0Logv3MixEX1Qx7PY2CrqNACHMYCw/s1600-h/image%255B2%255D"><img width="654" height="290" title="image" style="margin: 0px; display: inline; background-image: none;" alt="image" src="/posts/migrate/2017-12-25-data-science-series-07-deeper-look-at-yarn-and-hdfs-in-hadoop_Asset/image_thumb(66).png" border="0" class="img-responsive"></a><br><figcaption><span>圖片來源：                     <a href="https://pixabay.com/en/books-spine-colors-pastel-1099067/">https://pixabay.com/en/books-spine-colors-pastel-1099067/</a> 和                     <a href="https://pixabay.com/en/math-blackboard-education-classroom-1547018/">https://pixabay.com/en/math-blackboard-education-classroom-1547018/</a></span></figcaption><br></figure></section><section><p>在上一篇（<a style="line-height: 1.6; font-size: 15px;" href="http://blog.alantsai.net/2017/12/data-science-series-06-install-and-test-hadoop-part2.html">[06]建立Hadoop環境 -下篇</a><span style="line-height: 1.6; font-size: 15px;">）把hadoop             </span><em style="line-height: 1.6; font-size: 15px;">pseudo-distributed mode</em><span style="line-height: 1.6; font-size: 15px;">整個建立了起來，在這個過程中有透過             </span><em style="line-height: 1.6; font-size: 15px;">jps</em><span style="line-height: 1.6; font-size: 15px;">看到啟動的時候有5個process：</span></p><ol><li>NameNode</li><li>SecondaryNameNode</li><li>ResourceManager</li><li>NodeManager</li><li>DataNode</li></ol><p>這些process分別是yarn和HDFS執行起來的process，其中Master會有前             <em><strong>3個</strong></em>而slave有後             <em><strong>2個</strong></em></p><p>這篇將會對於這幾個問題做一些介紹。</p><div class="bs-callout bs-callout-warning">這篇提到的架構屬於Hadoop 2.x 版本的內容，Hadoop 3 之後有所變動。         </div></section><section><a name="KMContentPageTopID" id="KMContentPageTopID"></a><div id="divKMOutline" style="border-style: groove none; margin: 10px 0px;"><ul style="margin: 0px 0px 0px 20px;"><li><a style="line-height: 1.6; font-size: 15px;" href="#WizKMOutline_1514094423863565" ;="">Hadoop Cluster架構</a><br></li><li><a style="line-height: 1.6; font-size: 15px;" href="#WizKMOutline_1514094423863148" ;="">JobTracker和TaskTracker</a><br></li><ul style="margin: 0px 0px 0px 30px;"><li><a style="line-height: 1.6; font-size: 15px;" href="#WizKMOutline_1514094423863617" ;="">YARN - ResourceManager</a><br></li><li><a style="line-height: 1.6; font-size: 15px;" href="#WizKMOutline_1514094423863599" ;="">localhost:8088</a><br></li></ul><li><a style="line-height: 1.6; font-size: 15px;" href="#WizKMOutline_1514094423863306" ;="">NameNode、DataNode和Secondary NameNode</a><br></li><ul style="margin: 0px 0px 0px 30px;"><li><a style="line-height: 1.6; font-size: 15px;" href="#WizKMOutline_1514094423863621" ;="">Secondary NameNode呢？</a><br></li><li><a style="line-height: 1.6; font-size: 15px;" href="#WizKMOutline_1514094423863991" ;="">localhost:50070</a><br></li></ul><li><a style="line-height: 1.6; font-size: 15px;" href="#WizKMOutline_1514094423863980" ;="">結語</a><br></li></ul></div></section><a name="more"></a><section><h2 id="WizKMOutline_1514094423863565">Hadoop Cluster架構</h2><p>在介紹幾個jps之前，需要了解Hadoop Clusted的架構。         </p><p>Hadoop屬於Client/Server架構，基本上會有             <em><strong>一個Master</strong></em>，             <em><strong>多個slave</strong></em>。         </p><div class="bs-callout bs-callout-info">因為Master很重要，所以2.x版本可以為master做High Availability和Federation。         </div><p>在上一篇建立的屬於             <em>pseudo-distributed mode</em>，換句話說Master和Slave都是同一台，所以才看到了5個process。</p><p>以下圖來說，是一個Master配上兩個Slave。master和slave裡面又可以分開兩層：MapReduce 和 HDFS 層             </p><figure><a href="https://lh3.googleusercontent.com/-osWsuhxwLUk/WkD7ihTM6FI/AAAAAAAAXRU/bMMJFU-Nk1gsTbwmg0C_Oznwcep4CEpVACHMYCw/s1600-h/image%255B8%255D"><img width="654" height="455" title="image" style="display: inline; background-image: none;" alt="image" src="/posts/migrate/2017-12-25-data-science-series-07-deeper-look-at-yarn-and-hdfs-in-hadoop_Asset/image_thumb[4](45).png" border="0" class="img-responsive"></a><figcaption>不同層的內容。來源：http://saphanatutorial.com/how-yarn-overcomes-mapreduce-limitations-in-hadoop-2-0/</figcaption></figure><div class="bs-callout bs-callout-warning">注意，這邊的MapReduce層用的是Hadoop 1.x 的名稱。以2.0來說應該是YARN層。             </div></section><section><h2 id="WizKMOutline_1514094423863148">JobTracker和TaskTracker</h2><p>先來看看上面那層，可以看到：             </p><ul><li>JobTracker - 在Master</li><li>TaskTracker - 在Slave</li></ul><p>當一個工作被記錄的時候（例如呼叫WordCount.jar），會先進入到             <em>JobTracker</em>，再由JobTracker去             <em>切割</em>分派給 slave的             <em>TaskTracker</em>去做執行。最後TaskTracker在回報結果到JobTracker裡面。             </p><figure><a href="https://lh3.googleusercontent.com/-UrnsOJFhDi0/WkD7ljjVlHI/AAAAAAAAXRc/g0o-P30tPbEkjQSbxkd6eu-wKq19TuwSACHMYCw/s1600-h/image%255B13%255D"><img width="489" height="386" title="image" style="display: inline; background-image: none;" alt="image" src="/posts/migrate/2017-12-25-data-science-series-07-deeper-look-at-yarn-and-hdfs-in-hadoop_Asset/image_thumb[7](23).png" border="0" class="img-responsive"></a><figcaption>job分派情況，來源：http://saphanatutorial.com/mapreduce/</figcaption></figure><section><h3 id="WizKMOutline_1514094423863617">YARN - ResourceManager</h3><p>看到這邊，或許會奇怪，為什麼jps裡面沒有JobTracker和TaskTracker？原因是，JobTracker和TaskTracker是                 <em>MapReduce Layer</em>層的內容，而Hadoop 2.0加上了YARN，因此在jps看到的是                 <em><strong>ResourceManager</strong></em>和                 <em><strong>NodeManager</strong></em>。             </p><p>簡單來說，可以理解成為:                 </p><ol><li>JobTracker - ResourceManager</li><li>TaskTracker - NodeManager</li></ol></section><section><h3 id="WizKMOutline_1514094423863599">localhost:8088</h3><p>Port 8088是ResourceManager的UI界面</p><p>因此可以用瀏覽器看到目前：                 </p><ul><li>有幾個cluster - 幾個slave</li><li>有哪些工作</li><li>工作的執行情況</li></ul><p>因此，run起來之後可以用這個來檢查目前情況。             </p><figure><a href="https://lh3.googleusercontent.com/-hFcMOQHySVo/WkD7oR8vRrI/AAAAAAAAXRk/g5l-TDrkl0clTidOzc3KvTZWfxblYFmFgCHMYCw/s1600-h/image%255B16%255D"><img width="654" height="332" title="image" style="margin: 0px; display: inline; background-image: none;" alt="image" src="/posts/migrate/2017-12-25-data-science-series-07-deeper-look-at-yarn-and-hdfs-in-hadoop_Asset/image_thumb[8](21).png" border="0" class="img-responsive"></a><br><figcaption>8088的呈現畫面</figcaption></figure></section></section><section><h2 id="WizKMOutline_1514094423863306">NameNode、DataNode和Secondary NameNode</h2><p>基本上HDFS層和MapReduce層有一樣概念，不過這一次變成是儲存資料層的分散式儲存。         </p><ul><li>NameNode - 在Master</li><li>DataNode - 在Slave</li></ul><p>NameNode會記錄檔案<em><strong>分散</strong></em>在那幾個DataNode裡面。並且會透過<em><stron>replicate</stron>的方式把資料分成N份（一般是3份）儲存在不同DataNode達到檔案高可用性。             </em></p><p>以下圖來說，檔案被拆成了兩份：<em>A</em>和<em>C</em>，會自動被儲存在DataNode1~3，因此如果DataNode2掛掉了，NameNode會知道，並且             變成由DataNode1和DataNode3來處理。             </p><figure><a href="https://lh3.googleusercontent.com/-KQ8VD1R9V2M/WkD7rubV1ZI/AAAAAAAAXRs/qe-p0PBz8ME_-IcH9M6U_wmnWVIXbO7dgCHMYCw/s1600-h/image%255B21%255D"><img width="606" height="214" title="image" style="display: inline; background-image: none;" alt="image" src="/posts/migrate/2017-12-25-data-science-series-07-deeper-look-at-yarn-and-hdfs-in-hadoop_Asset/image_thumb[11](12).png" border="0" class="img-responsive"></a><figcaption>NameNode和DataNode的關係。來源：https://www.quora.com/Explain-what-is-NameNode-in-Hadoop</figcaption></figure><section><h3 id="WizKMOutline_1514094423863621">Secondary NameNode呢？</h3><p>上面介紹了NameNode和DataNode，那麼Secondary NameNode呢？             </p><p>Secondary NameNode用來提供一個<em>Checkpoint</em>輔助NameNode處理資料。             </p><p>因此Secondary NameNode不是備份用，因此為了避免誤會有時候會成為<em>Checkpoint Node</em><span style="line-height: 1.6; font-size: 15px;">。</span></p></section><section><h3 id="WizKMOutline_1514094423863991">localhost:50070</h3><p>Port 50070是NameNode的一個web UI界面</p><p>在這個界面裡面可以看到DataNode有幾台，並且有幾台死掉了等資訊。</p><figure><a href="https://lh3.googleusercontent.com/-AOxHKKnWdNM/WkD7xf4pWdI/AAAAAAAAXR0/UHEhY-UT7QUB30G0yPcd1QcAJD6nCBM0wCHMYCw/s1600-h/image%255B24%255D"><img width="654" height="412" title="image" style="margin: 0px; display: inline; background-image: none;" alt="image" src="/posts/migrate/2017-12-25-data-science-series-07-deeper-look-at-yarn-and-hdfs-in-hadoop_Asset/image_thumb[12](14).png" border="0" class="img-responsive"></a><br><figcaption>50070的畫面</figcaption></figure></section></section><section><h2 id="WizKMOutline_1514094423863980">結語</h2><p>希望透過這篇對於底層的jps process有些了解，並且對於hadoop的cluster更有感覺。         </p><p>在下一篇(<a href="http://blog.alantsai.net/2017/12/data-science-series-08-hadoop-fully-distributed-mode-tutorial.html">[08]Hadoop 改成完全分散模式</a>)，將會回到實際操作的部分，不過這次實際建立一個完整的cluster。Master那台本身是一台slave然後建立另外一台純粹是slave的機器。         </p></section><section>             <div class="wlWriterEditableSmartContent" id="scid:77ECF5F8-D252-44F5-B4EB-D463C5396A79:6ba9b4fb-981d-4c19-91be-174db59bfd7f" style="margin: 0px; padding: 0px; float: none; display: inline;">標籤: <a href="/tags/%e3%80%8cData+Science+%e5%88%b0%e5%ba%95%e6%98%af%e4%bb%80%e9%ba%bc%e5%be%9e%e4%b8%80%e5%80%8b%e5%ae%8c%e5%85%a8%e5%a4%96%e8%a1%8c%e8%a7%92%e5%ba%a6%e4%be%86%e7%9c%8b%e3%80%8d" rel="tag">「Data Science 到底是什麼從一個完全外行角度來看」</a>,<a href="/tags/data+science" rel="tag">data science</a>,<a href="/tags/hadoop" rel="tag">hadoop</a></div></section>